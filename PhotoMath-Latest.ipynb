{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12,13):\n",
    "    img = cv2.imread(\"images/\"+str(i)+\".jpg\", 0)\n",
    "    gblur = cv2.GaussianBlur(img, (11,11), 0)\n",
    "    ret,thresh1 = cv2.threshold(gblur,127,255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh1,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        #bound the images\n",
    "        cv2.rectangle(img,(x-15,y-15),(x+w+15,y+h+15),(0,255,0),3)\n",
    "    j = 1\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        #following if statement is to ignore the noises and save the images which are of normal size(character)\n",
    "        #In order to write more general code, than specifying the dimensions as 100,\n",
    "        # number of characters should be divided by word dimension\n",
    "        if (w>40 and h>40)or(w>100 and h<30): \n",
    "            #save individual images\n",
    "            cv2.imwrite(\"new_dataset/\"+str(i)+\"/\"+str(j)+\".jpg\",thresh1[y-15:y+h+15,x-15:x+w+15])\n",
    "            j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image exists: True\n"
     ]
    }
   ],
   "source": [
    "# To make seperate contour images inti new dataset\n",
    "for i in range(13,14):\n",
    "    exists = os.path.isfile(\"images/\"+str(i)+\".jpg\")\n",
    "    print(\"image exists:\", exists)\n",
    "    if exists:\n",
    "        img = cv2.imread(\"images/\"+str(i)+\".jpg\", 0)\n",
    "        gblur = cv2.GaussianBlur(img, (11,11), 0)\n",
    "        ret,thresh1 = cv2.threshold(gblur,127,255,cv2.THRESH_BINARY)\n",
    "        contours, hierarchy = cv2.findContours(thresh1,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        j = 0\n",
    "        for cnt in contours:\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            #bound the images\n",
    "            cv2.rectangle(img,(x-10,y-10),(x+w+10,y+h+10),(0,255,0),3)\n",
    "            if (w>10 and h>10):#or(w>100 and h<30): \n",
    "                #save individual images\n",
    "                cv2.imwrite(\"new_dataset/\"+str(i)+\"/\"+str(j)+\".jpg\",thresh1[y-10:y+h+10,x-10:x+w+10])\n",
    "                j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_contours(img):\n",
    "    gblur = cv2.GaussianBlur(img, (11,11), 0)\n",
    "    ret,thresh1 = cv2.threshold(gblur,127,255,cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh1,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expression(contour):\n",
    "    for cnt in contour:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    #bound the images\n",
    "    cv2.rectangle(img,(x-15,y-15),(x+w+15,y+h+15),(0,255,0),3)\n",
    "    #following if statement is to ignore the noises and save the images which are of normal size(character)\n",
    "    #In order to write more general code, than specifying the dimensions as 100,\n",
    "    # number of characters should be divided by word dimension\n",
    "    if (w>50 and h>50):#or(w>100 and h<30): \n",
    "        #save individual images\n",
    "        cv2.imwrite(str(j)+\".jpg\",thresh1[y-15:y+h+15,x-15:x+w+15])\n",
    "        j=j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids():\n",
    "    centroids = []\n",
    "    for cnt in contours:\n",
    "        M = cv2.moments(cnt)\n",
    "        Cx = M['m10']/M['m00']\n",
    "        Cy = M['m01']/M['m00']\n",
    "        centroids.append((Cx, Cy, cnt))\n",
    "    return centroids    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(0,10):\n",
    "    for j in range(1,60):\n",
    "        exists = os.path.isfile('new_dataset/'+str(i)+'/'+str(j)+'.jpg')\n",
    "        if exists:\n",
    "            img = cv2.imread('new_dataset/'+str(i)+'/'+str(j)+'.jpg', 0)\n",
    "            resized_img = cv2.resize(255-img, (28,28), interpolation=cv2.INTER_AREA)\n",
    "            img_unrolled = resized_img.ravel()\n",
    "            X.append(img_unrolled)\n",
    "            Y.append(i)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                        PREDICTION USING CONVOLUTION NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PREPROCESSING\n",
    "\n",
    "## 1. Splitting our complete Dataset into three sets:-\n",
    "# training set, a validation set and a test set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train = 70% and val_and_test size will be 30% of the overall dataset\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# size of val and test each will be 50% of val_test i.e 15% of whole dataset\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Reshaping and Normalisation\n",
    "\n",
    "#reshape data to fit model\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)  \n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential([\n",
    "    Conv2D(28, kernel_size=(3,3), input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=tf.nn.relu),\n",
    "    Dropout(0.2),\n",
    "    Dense(10,activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring the model with these settings\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on Data\n",
    "\n",
    "hist = model.fit(X_train, Y_train, # data we are training on\n",
    "                batch_size=10, epochs=15, # specify the size of our mini-batch and how long we want to train it for (epochs)\n",
    "                validation_data=(X_val, Y_val)) # model will tell us how we are doing on the validation data \n",
    "\n",
    "# At this point, we can experiment with our model(changing hyperparametrs) to check accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3714092016220093\n",
      "Test accuracy: 0.950000007947286\n"
     ]
    }
   ],
   "source": [
    "# Testing our model on test-set\n",
    "\n",
    "#  index 1 after the model.evaluate function is because\n",
    "#  the function returns the loss as the first element and the accuracy as the second element.\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) # second element\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 28, 28, 1)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing on Real World Images\n",
    "\n",
    "# img = cv2.imread('6.jpg', 0)\n",
    "# resized_img = cv2.resize(255-img, (28,28), interpolation=cv2.INTER_AREA)\n",
    "# img_unrolled = resized_img.ravel()\n",
    "# X = [img_unrolled] / 255\n",
    "# Y = [6]\n",
    "\n",
    "# X = X.reshape(X.shape[0], 28, 28, 1)\n",
    "# X = X.astype('float32')\n",
    "\n",
    "# print(X_test.shape)\n",
    "# print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTION USING ARTIFICIAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-PROCESSING FOR ANN\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Scaling\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale\n",
    "\n",
    "## 4. Splitting our complete Dataset into three sets:-\n",
    "# training set, a validation set and a test set.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train = 70% and val_and_test size will be 30% of the overall dataset\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "\n",
    "# size of val and test each will be 50% of val_test i.e 15% of whole dataset\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### BUILDING AND TRAINING OUR NEURAL NETWORK\n",
    "\n",
    "## 1. First Step: Setting up the Architecture\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Specifying our Architecture(model) Sequentially\n",
    "#  â€˜Denseâ€™ refers to a fully-connected layer\n",
    "\n",
    "# Hidden layer 1: 50 neurons, ReLU activation\n",
    "# Hidden layer 2: 50 neurons, ReLU activation\n",
    "# Output Layer: 1 neuron, Sigmoid activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(784,)), # Hidden layer-1\n",
    "    Dense(50, activation='relu'), # Hidden layer-2\n",
    "    Dense(10, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "## 2. Second Step: Filling in the best numbers\n",
    "\n",
    "# Configuring the model with these settings\n",
    "\n",
    "model.compile(optimizer='sgd', # sgd = stochastic gradient descent\n",
    "              loss='sparse_categorical_crossentropy', # The loss function for outputs that take the values 0 to 10\n",
    "              metrics=['accuracy']) # to track accuracy on top of the loss function\n",
    "\n",
    "\n",
    "# Training on Data\n",
    "\n",
    "hist = model.fit(X_train, Y_train, # data we are training on\n",
    "                batch_size=10, epochs=50, # specify the size of our mini-batch and how long we want to train it for (epochs)\n",
    "                validation_data=(X_val, Y_val)) # model will tell us how we are doing on the validation data \n",
    "\n",
    "# At this point, we can experiment with our model(changing hyperparametrs) to check accuracy.\n",
    "\n",
    "# Testing our model on test-set\n",
    "\n",
    "#  index 1 after the model.evaluate function is because\n",
    "#  the function returns the loss as the first element and the accuracy as the second element.\n",
    "\n",
    "model.evaluate(X_test, Y_test)[1] # second element\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
